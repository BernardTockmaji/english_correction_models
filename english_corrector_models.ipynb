{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries & Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#For Implementing Gramformer Solution\n",
    "from gramformer import Gramformer\n",
    "\n",
    "#for implementing Bert Solution\n",
    "from happytransformer import HappyTextToText, TTSettings\n",
    "\n",
    "#For Implementing LanguageTool Solution\n",
    "import language_tool_python\n",
    "\n",
    "#For GingerIt Solution\n",
    "from gingerit.gingerit import GingerIt\n",
    "\n",
    "#For Symspellpy\n",
    "import pkg_resources\n",
    "from symspellpy import SymSpell\n",
    "\n",
    "#For TextBlob\n",
    "from textblob import TextBlob\n",
    "\n",
    "#For Web Application Development\n",
    "import gradio as gr\n",
    "\n",
    "import pandas as pd\n",
    "import sys \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./grammatical error detection/NLP Assignment/test_data.csv')\n",
    "df.head(20)\n",
    "test_df = df.head(40)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gramformer Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gramformer] Grammar error correct/highlight model loaded..\n"
     ]
    }
   ],
   "source": [
    "gf = Gramformer(models=1, use_gpu=False) #1=corrector, 2=detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hello my dear child.'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gf.correct('hello my dear childs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Function to build web application using gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct(sentence):\n",
    "    res = gf.correct(sentence) \n",
    "    return res\n",
    "# app_inputs = gr.inputs.Textbox(lines=3, placeholder=\"Enter a grammatically incorrect sentence here...\")\n",
    "\n",
    "# interface = gr.Interface(fn=correct, \n",
    "#                         inputs=app_inputs,\n",
    "#                          outputs='text', \n",
    "#                         title='Hi there, I\\'m Gramformer')\n",
    "\n",
    "#interface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Gramformer highlighter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gh = Gramformer(models=3, use_gpu=False) #1=corrector, 2=detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gh.highlight(orig='to tha store',cor='to the store')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying Gramformer on Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gramformer_corrector(text):\n",
    "    res = gf.correct(text) \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Calling Gramformer model for correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df['corrected_sentence'] = test_df['input'].apply(lambda text: gramformer_corrector(text))\n",
    "# test_df.head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bert + Huggingface Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This sentence has bad grammar.\n"
     ]
    }
   ],
   "source": [
    "happy_tt = HappyTextToText(\"T5\", \"vennify/t5-base-grammar-correction\")\n",
    "args = TTSettings(num_beams=5, min_length=1)\n",
    "result = happy_tt.generate_text(\"grammar: This sentences has has bads grammar.\", args=args)\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huggingface_corrector(text):\n",
    "    result = happy_tt.generate_text('grammar: ' + text, args=TTSettings(num_beams=1, min_length=1, max_length=100))\n",
    "    return result.text\n",
    "# app_hugginface_inputs = gr.inputs.Textbox(lines=3, placeholder=\"Enter a grammatically incorrect sentence here...\")\n",
    "\n",
    "# interface2 = gr.Interface(fn=huggingface_corrector, \n",
    "#                         inputs=app_hugginface_inputs,\n",
    "#                         outputs='text', \n",
    "#                         title='Hi there, I\\'m Huggingface')\n",
    "\n",
    "#interface2.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying Bert + Hugging Face on Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huggingface_corrector(text):\n",
    "    result = happy_tt.generate_text('grammar: ' + text, args=TTSettings(num_beams=1, min_length=1, max_length=100))\n",
    "    return result.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Calling Bert model for correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df['corrected_sentence'] = test_df['input'].apply(lambda text: huggingface_corrector(text))\n",
    "# test_df.head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Tool Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tool = language_tool_python.LanguageTool('en-US')  \n",
    "my_text = \"\"\"LanguageTool provides utility to check grammar and spelling errors. We just have to paste the text here and click the 'Check Text' button. Click the colored phrases for for information on potential errors. or we can use this text too see an some of the issues that LanguageTool can dedect. Whot do someone thinks of grammar checkers? Please not that they are not perfect. Style problems get a blue marker: It is 7 P.M. in the evening. The weather was nice on Monday, 22 November 2021\"\"\"   \n",
    "\n",
    "def english_text_corrector(tool, text):\n",
    "    \n",
    "    matches = tool.check(text)\n",
    "\n",
    "    #empty lists\n",
    "    Mistakes = [] \n",
    "    Corrections = []  \n",
    "    StartPositions = []  \n",
    "    EndPositions = []  \n",
    "\n",
    "    for rules in matches:\n",
    "        if len(rules.replacements) > 0:  \n",
    "            StartPositions.append(rules.offset)  \n",
    "            EndPositions.append(rules.errorLength + rules.offset)  \n",
    "            Mistakes.append(my_text[rules.offset : rules.errorLength + rules.offset])  \n",
    "            Corrections.append(rules.replacements[0]) \n",
    "\n",
    "    print(\"Mistakes made\")\n",
    "    print (Mistakes)\n",
    "    print (\"\\nRecommended Corrections\")\n",
    "    print(Corrections)\n",
    "    print (\"\\nMistake Starting character number\")\n",
    "    print(StartPositions)\n",
    "    print (\"\\nMistake EndPoint character number\")\n",
    "    print(EndPositions)\n",
    "\n",
    "    mistakes_number = len (Mistakes)\n",
    "\n",
    "    print( \"\\nNumber of mistakes made \" + str(mistakes_number))\n",
    "    #return mistakes_number\n",
    "\n",
    "#english_text_corrector(my_tool, my_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Tool Model on Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "def language_tool_corrector(text:str):\n",
    "    correction = tool.correct(text)\n",
    "    return correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Calling language tool model for correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df['corrected_sentence'] = test_df['input'].apply(lambda text: language_tool_corrector(text))\n",
    "# test_df.head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GingerIt Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The smell of flowers brings back memories.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'The smelt of fliwers bring back memories.'\n",
    "\n",
    "parser = GingerIt()\n",
    "parser.parse(text)['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying GingerIt Model on Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ginger_corrector(text: str):\n",
    "    \n",
    "    parser = GingerIt()\n",
    "    correction = parser.parse(text)['result']\n",
    "    return correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Calling GingerIt model for correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df['corrected_sentence'] = test_df['input'].apply(lambda text: ginger_corrector(text))\n",
    "# test_df.head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symspellpy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "where is the love he had dated for much of the past who couldn't read in six grade and inspired him, 9, 0\n"
     ]
    }
   ],
   "source": [
    "sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
    "dictionary_path = pkg_resources.resource_filename(\n",
    "    \"symspellpy\", \"frequency_dictionary_en_82_765.txt\"\n",
    ")\n",
    "bigram_path = pkg_resources.resource_filename(\n",
    "    \"symspellpy\", \"frequency_bigramdictionary_en_243_342.txt\"\n",
    ")\n",
    "# term_index is the column of the term and count_index is the\n",
    "# column of the term frequency\n",
    "sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
    "sym_spell.load_bigram_dictionary(bigram_path, term_index=0, count_index=2)\n",
    "input_term = (\n",
    "    \"whereis th elove hehad dated forImuch of thepast who \"\n",
    "    \"couqdn'tread in sixtgrade and ins pired him\"\n",
    ")\n",
    "# max edit distance per lookup (per single word, not per whole input string)\n",
    "suggestions = sym_spell.lookup_compound(input_term, max_edit_distance=2)\n",
    "\n",
    "for suggestion in suggestions:\n",
    "    print(suggestion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def symspelly_corrector(text):\n",
    "    sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
    "    dictionary_path = pkg_resources.resource_filename(\n",
    "        \"symspellpy\", \"frequency_dictionary_en_82_765.txt\"\n",
    "    )\n",
    "    bigram_path = pkg_resources.resource_filename(\n",
    "        \"symspellpy\", \"frequency_bigramdictionary_en_243_342.txt\"\n",
    "    )\n",
    "\n",
    "    sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
    "    sym_spell.load_bigram_dictionary(bigram_path, term_index=0, count_index=2)\n",
    "    suggestions = sym_spell.lookup_compound(text, max_edit_distance=2)\n",
    "\n",
    "    for suggestion in suggestions:\n",
    "        return suggestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df['corrected_sentence'] = test_df['input'].apply(lambda text: symspelly_corrector(text))\n",
    "# test_df.head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textblob_corrector(text):\n",
    "    correction = TextBlob(text)\n",
    "    return correction.correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df['ginger_corrected_sentence'] = test_df['input'].apply(lambda text: textblob_corrector(text))\n",
    "# test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining GingerIt with Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df['ginger_corrected_sentence'] = test_df['input'].apply(lambda text: ginger_corrector(text))\n",
    "# test_df['combined_with_bert_corrected_sentence'] = test_df['ginger_corrected_sentence'].apply(lambda text: huggingface_corrector(text))\n",
    "# test_df.head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Gingerit with Gramformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df['ginger_corrected_sentence'] = test_df['input'].apply(lambda text: ginger_corrector(text))\n",
    "# test_df['combined_with_gramformer'] = test_df['ginger_corrected_sentence'].apply(lambda text: gramformer_corrector(text))\n",
    "# test_df.head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_df = pd.read_csv(\"./grammar_error_check.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error</th>\n",
       "      <th>real_correct</th>\n",
       "      <th>predicted_correct</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>diff_r</th>\n",
       "      <th>diff_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D 'Souza is amaced at the recognitaon eancing now has in India -- and the money involked .</td>\n",
       "      <td>D 'Souza is amazed at the recognition dancing now has in India -- and the money involved .</td>\n",
       "      <td>D'Souza is amazed at the recognition, dancing now has in India -- and the money invoked.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'recognition', 'amazed', 'involved', 'dancing'}</td>\n",
       "      <td>{'recognition,', 'amazed', 'invoked.', 'dancing', \"D'Souza\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Similarly , the United States gav Ge0rgia military aid in 2002 and 2003 to gelp mprove caunterterror capabilities .</td>\n",
       "      <td>Similarly , the United States gave Georgia military aid in 2002 and 2003 to help improve counterterror capabilities .</td>\n",
       "      <td>Similarly, the United States gave Georgia military aid in 2002 and 2003 to help improve its combat capabilities.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'help', 'counterterror', 'improve', 'Georgia', 'gave'}</td>\n",
       "      <td>{'help', 'improve', 'combat', 'capabilities.', 'Georgia', 'its', 'Similarly,', 'gave'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Others fear the neighbourhood 's character will be irseparabey changed because of luxury housing .</td>\n",
       "      <td>Others fear the neighbourhood 's character will be irreparably changed because of luxury housing .</td>\n",
       "      <td>Others fear the neighborhood's character will be irreparabey changed because of luxury housing.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'irreparably'}</td>\n",
       "      <td>{\"neighborhood's\", 'irreparabey', 'housing.'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Goldman reported from New York .</td>\n",
       "      <td>Goldman reported from New York .</td>\n",
       "      <td>Goldman reported from New York.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>set()</td>\n",
       "      <td>{'York.'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>But there 's no oubt that Dudley , im he runs , would bring name familiarity to the rac given that he had two stints playing for the Trail Blazers , from 1993-97 and from 2001-03 .</td>\n",
       "      <td>But there 's no doubt that Dudley , if he runs , would bring name familiarity to the race given that he had two stints playing for the Trail Blazers , from 1993-97 and from 2001-03 .</td>\n",
       "      <td>But there's no doubt that Dudley, I'm he runs, would bring name familiarity to the race given that he had two stints playing for the Trail Blazers, from 1993-97 and from 2001-03.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'if', 'doubt', 'race'}</td>\n",
       "      <td>{\"there's\", 'Dudley,', 'runs,', 'doubt', \"I'm\", '2001-03.', 'Blazers,', 'race'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                  error  \\\n",
       "0                                                                                            D 'Souza is amaced at the recognitaon eancing now has in India -- and the money involked .   \n",
       "1                                                                   Similarly , the United States gav Ge0rgia military aid in 2002 and 2003 to gelp mprove caunterterror capabilities .   \n",
       "2                                                                                    Others fear the neighbourhood 's character will be irseparabey changed because of luxury housing .   \n",
       "3                                                                                                                                                      Goldman reported from New York .   \n",
       "4  But there 's no oubt that Dudley , im he runs , would bring name familiarity to the rac given that he had two stints playing for the Trail Blazers , from 1993-97 and from 2001-03 .   \n",
       "\n",
       "                                                                                                                                                                             real_correct  \\\n",
       "0                                                                                              D 'Souza is amazed at the recognition dancing now has in India -- and the money involved .   \n",
       "1                                                                   Similarly , the United States gave Georgia military aid in 2002 and 2003 to help improve counterterror capabilities .   \n",
       "2                                                                                      Others fear the neighbourhood 's character will be irreparably changed because of luxury housing .   \n",
       "3                                                                                                                                                        Goldman reported from New York .   \n",
       "4  But there 's no doubt that Dudley , if he runs , would bring name familiarity to the race given that he had two stints playing for the Trail Blazers , from 1993-97 and from 2001-03 .   \n",
       "\n",
       "                                                                                                                                                                    predicted_correct  \\\n",
       "0                                                                                            D'Souza is amazed at the recognition, dancing now has in India -- and the money invoked.   \n",
       "1                                                                    Similarly, the United States gave Georgia military aid in 2002 and 2003 to help improve its combat capabilities.   \n",
       "2                                                                                     Others fear the neighborhood's character will be irreparabey changed because of luxury housing.   \n",
       "3                                                                                                                                                     Goldman reported from New York.   \n",
       "4  But there's no doubt that Dudley, I'm he runs, would bring name familiarity to the race given that he had two stints playing for the Trail Blazers, from 1993-97 and from 2001-03.   \n",
       "\n",
       "  Unnamed: 3                                                   diff_r  \\\n",
       "0        NaN         {'recognition', 'amazed', 'involved', 'dancing'}   \n",
       "1        NaN  {'help', 'counterterror', 'improve', 'Georgia', 'gave'}   \n",
       "2        NaN                                          {'irreparably'}   \n",
       "3        NaN                                                    set()   \n",
       "4        NaN                                  {'if', 'doubt', 'race'}   \n",
       "\n",
       "                                                                                   diff_p  \n",
       "0                            {'recognition,', 'amazed', 'invoked.', 'dancing', \"D'Souza\"}  \n",
       "1  {'help', 'improve', 'combat', 'capabilities.', 'Georgia', 'its', 'Similarly,', 'gave'}  \n",
       "2                                           {\"neighborhood's\", 'irreparabey', 'housing.'}  \n",
       "3                                                                               {'York.'}  \n",
       "4         {\"there's\", 'Dudley,', 'runs,', 'doubt', \"I'm\", '2001-03.', 'Blazers,', 'race'}  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_df.drop(columns=['Unnamed: 3', 'diff_r', 'diff_p'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_df['corrected_sentence'] = grammar_df['error'].apply(lambda text: huggingface_corrector(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error</th>\n",
       "      <th>real_correct</th>\n",
       "      <th>predicted_correct</th>\n",
       "      <th>corrected_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D 'Souza is amaced at the recognitaon eancing now has in India -- and the money involked .</td>\n",
       "      <td>D 'Souza is amazed at the recognition dancing now has in India -- and the money involved .</td>\n",
       "      <td>D'Souza is amazed at the recognition, dancing now has in India -- and the money invoked.</td>\n",
       "      <td>D'Souza is happy at the recognition he now has in India -- and the money involved.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Similarly , the United States gav Ge0rgia military aid in 2002 and 2003 to gelp mprove caunterterror capabilities .</td>\n",
       "      <td>Similarly , the United States gave Georgia military aid in 2002 and 2003 to help improve counterterror capabilities .</td>\n",
       "      <td>Similarly, the United States gave Georgia military aid in 2002 and 2003 to help improve its combat capabilities.</td>\n",
       "      <td>Similarly, the United States gave the United States military aid in 2002 and 2003 to improve its defense capabilities.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Others fear the neighbourhood 's character will be irseparabey changed because of luxury housing .</td>\n",
       "      <td>Others fear the neighbourhood 's character will be irreparably changed because of luxury housing .</td>\n",
       "      <td>Others fear the neighborhood's character will be irreparabey changed because of luxury housing.</td>\n",
       "      <td>Others fear the neighbourhood's character will be irreplaceable because of luxury housing.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                 error  \\\n",
       "0                           D 'Souza is amaced at the recognitaon eancing now has in India -- and the money involked .   \n",
       "1  Similarly , the United States gav Ge0rgia military aid in 2002 and 2003 to gelp mprove caunterterror capabilities .   \n",
       "2                   Others fear the neighbourhood 's character will be irseparabey changed because of luxury housing .   \n",
       "\n",
       "                                                                                                            real_correct  \\\n",
       "0                             D 'Souza is amazed at the recognition dancing now has in India -- and the money involved .   \n",
       "1  Similarly , the United States gave Georgia military aid in 2002 and 2003 to help improve counterterror capabilities .   \n",
       "2                     Others fear the neighbourhood 's character will be irreparably changed because of luxury housing .   \n",
       "\n",
       "                                                                                                  predicted_correct  \\\n",
       "0                          D'Souza is amazed at the recognition, dancing now has in India -- and the money invoked.   \n",
       "1  Similarly, the United States gave Georgia military aid in 2002 and 2003 to help improve its combat capabilities.   \n",
       "2                   Others fear the neighborhood's character will be irreparabey changed because of luxury housing.   \n",
       "\n",
       "                                                                                                       corrected_sentence  \n",
       "0                                      D'Souza is happy at the recognition he now has in India -- and the money involved.  \n",
       "1  Similarly, the United States gave the United States military aid in 2002 and 2003 to improve its defense capabilities.  \n",
       "2                              Others fear the neighbourhood's character will be irreplaceable because of luxury housing.  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'error_analysis.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [62], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mspell error detection/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(grammar_df)\n\u001b[1;32m----> 3\u001b[0m data\u001b[39m.\u001b[39;49mto_csv(\u001b[39m'\u001b[39;49m\u001b[39merror_analysis.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\envs\\correct-env\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\envs\\correct-env\\lib\\site-packages\\pandas\\core\\generic.py:3720\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3709\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[0;32m   3711\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3712\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[0;32m   3713\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3717\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[0;32m   3718\u001b[0m )\n\u001b[1;32m-> 3720\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[0;32m   3721\u001b[0m     path_or_buf,\n\u001b[0;32m   3722\u001b[0m     lineterminator\u001b[39m=\u001b[39;49mlineterminator,\n\u001b[0;32m   3723\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[0;32m   3724\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m   3725\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   3726\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m   3727\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[0;32m   3728\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   3729\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[0;32m   3730\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[0;32m   3731\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m   3732\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[0;32m   3733\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[0;32m   3734\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[0;32m   3735\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[0;32m   3736\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m   3737\u001b[0m )\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\envs\\correct-env\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\envs\\correct-env\\lib\\site-packages\\pandas\\io\\formats\\format.py:1189\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1168\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1171\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1172\u001b[0m     lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1187\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[0;32m   1188\u001b[0m )\n\u001b[1;32m-> 1189\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[0;32m   1191\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1192\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\envs\\correct-env\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:241\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[39mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[39m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m    242\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilepath_or_buffer,\n\u001b[0;32m    243\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    244\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    245\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,\n\u001b[0;32m    246\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompression,\n\u001b[0;32m    247\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstorage_options,\n\u001b[0;32m    248\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[0;32m    249\u001b[0m \n\u001b[0;32m    250\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[0;32m    252\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m    253\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[0;32m    259\u001b[0m     )\n\u001b[0;32m    261\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\envs\\correct-env\\lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'error_analysis.csv'"
     ]
    }
   ],
   "source": [
    "path = \"spell error detection/\"\n",
    "data = pd.DataFrame(grammar_df)\n",
    "data.to_csv('error_analysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('correct-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4374edbdce5cf0ebc5572306dfb5843c5403ff613b25869cdbf8c66a66663275"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
